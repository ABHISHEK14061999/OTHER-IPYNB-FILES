{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ArWK463kbhL",
    "outputId": "ad250ffe-29ed-4dc9-bf30-fe91ab10656c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mldzJdakbhS"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_b.csv')\n",
    "data=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsCrC2wckbhV",
    "outputId": "fff03fba-880e-4875-9bba-f05797f08d1d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-195.871045</td>\n",
       "      <td>-14843.084171</td>\n",
       "      <td>5.532140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1217.183964</td>\n",
       "      <td>-4068.124621</td>\n",
       "      <td>4.416082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.138451</td>\n",
       "      <td>4413.412028</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.824242</td>\n",
       "      <td>15474.760647</td>\n",
       "      <td>1.094119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-768.812047</td>\n",
       "      <td>-7963.932192</td>\n",
       "      <td>1.870536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1            f2        f3    y\n",
       "0  -195.871045 -14843.084171  5.532140  1.0\n",
       "1 -1217.183964  -4068.124621  4.416082  1.0\n",
       "2     9.138451   4413.412028  0.425317  0.0\n",
       "3   363.824242  15474.760647  1.094119  0.0\n",
       "4  -768.812047  -7963.932192  1.870536  0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FI18joJ_kbhZ",
    "outputId": "22e420e9-4295-4307-a60f-1a528d07c81d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1    0.067172\n",
       "f2   -0.017944\n",
       "f3    0.839060\n",
       "y     1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u40oCVMikbhc",
    "outputId": "db6dce7e-7469-4aa5-8af3-1c08cd0f0081",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1      488.195035\n",
       "f2    10403.417325\n",
       "f3        2.926662\n",
       "y         0.501255\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQIbNaHskbhe",
    "outputId": "f2298482-b1d5-47e0-f15c-31f4a753a9ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "X=data[['f1','f2','f3']].values\n",
    "Y=data['y'].values\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUxp9-qEkbhh"
   },
   "source": [
    "# What if our features are with different variance \n",
    "\n",
    "<pre>\n",
    "* <b>As part of this task you will observe how linear models work in case of data having feautres with different variance</b>\n",
    "* <b>from the output of the above cells you can observe that var(F2)>>var(F1)>>Var(F3)</b>\n",
    "\n",
    "> <b>Task1</b>:\n",
    "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' and check the feature importance\n",
    "    2. Apply SVM(SGDClassifier with hinge) on 'data' and check the feature importance\n",
    "\n",
    "> <b>Task2</b>:\n",
    "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' after standardization \n",
    "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
    "    2. Apply SVM(SGDClassifier with hinge) on 'data' after standardization \n",
    "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbMnsrxakbhi"
   },
   "source": [
    "<h3><font color='blue'> Make sure you write the observations for each task, why a particular feautre got more importance than others</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1] Task 1Â¶\n",
    "## [1.1] Logistic regression(SGDClassifier with logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lr_clsfr: Logistic Rgression classifier\n",
    "\"\"\"\n",
    "lr_clsfr = linear_model.SGDClassifier(loss='log', eta0 = 0.0001, alpha = 0.0001, penalty = 'l2', random_state = 15, verbose = 2, n_jobs = -1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Data Type of d_train: {} [<class 'numpy.ndarray'>]\n",
      "2. Shape of d_train: {}\n",
      "\n",
      " [(200, 3)]\n",
      "1. Data Type of y: {} [<class 'numpy.ndarray'>]\n",
      "2. Shape of y:  [(200, 1)]\n"
     ]
    }
   ],
   "source": [
    "d_train = data[['f1', 'f2', 'f3']].values\n",
    "print(\"1. Data Type of d_train: {}\", [type(d_train)])\n",
    "print(\"2. Shape of d_train: {}\\n\\n\", [d_train.shape])\n",
    "\n",
    "y = data[['y']].values\n",
    "print(\"1. Data Type of y: {}\", [type(y)])\n",
    "print(\"2. Shape of y: \", [y.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's reshape y dimension from 2-D array to vector\n",
    "\"\"\"\n",
    "y = y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 89870.22, NNZs: 3, Bias: -155.051327, T: 200, Avg. loss: 227510618.879137\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 43791.04, NNZs: 3, Bias: -144.898405, T: 400, Avg. loss: 200670830.244106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21826.51, NNZs: 3, Bias: -167.580253, T: 600, Avg. loss: 220221238.438343\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44052.83, NNZs: 3, Bias: -220.577819, T: 800, Avg. loss: 179903697.744537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43829.42, NNZs: 3, Bias: -246.905532, T: 1000, Avg. loss: 159178154.202827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 45138.87, NNZs: 3, Bias: -208.546352, T: 1200, Avg. loss: 142129650.458868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27699.02, NNZs: 3, Bias: -168.679560, T: 1400, Avg. loss: 134776289.480256\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 30003.76, NNZs: 3, Bias: -147.095138, T: 1600, Avg. loss: 122695625.336222\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40159.27, NNZs: 3, Bias: -173.114320, T: 1800, Avg. loss: 105392821.686273\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 18380.20, NNZs: 3, Bias: -173.985270, T: 2000, Avg. loss: 109406423.687877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 33614.14, NNZs: 3, Bias: -151.697668, T: 2200, Avg. loss: 104611163.295840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 28081.35, NNZs: 3, Bias: -167.072934, T: 2400, Avg. loss: 84531652.656471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 49666.61, NNZs: 3, Bias: -189.824733, T: 2600, Avg. loss: 90663895.072324\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57159.43, NNZs: 3, Bias: -155.164527, T: 2800, Avg. loss: 73300728.123771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 24516.31, NNZs: 3, Bias: -142.245980, T: 3000, Avg. loss: 61143613.980263\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 15015.86, NNZs: 3, Bias: -159.140627, T: 3200, Avg. loss: 71025642.232696\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 20462.44, NNZs: 3, Bias: -168.751459, T: 3400, Avg. loss: 62715215.539027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28659.44, NNZs: 3, Bias: -171.142036, T: 3600, Avg. loss: 59523726.187933\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 26592.00, NNZs: 3, Bias: -175.112527, T: 3800, Avg. loss: 60215259.923806\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 15589.86, NNZs: 3, Bias: -193.384867, T: 4000, Avg. loss: 56474001.620423\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16065.45, NNZs: 3, Bias: -213.149785, T: 4200, Avg. loss: 48442814.077230\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 14069.21, NNZs: 3, Bias: -190.144797, T: 4400, Avg. loss: 50351240.172419\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9920.91, NNZs: 3, Bias: -188.148064, T: 4600, Avg. loss: 43039365.439501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12013.89, NNZs: 3, Bias: -195.017494, T: 4800, Avg. loss: 54210598.721807\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 30388.34, NNZs: 3, Bias: -191.521585, T: 5000, Avg. loss: 41931376.234027\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 18244.54, NNZs: 3, Bias: -199.584009, T: 5200, Avg. loss: 42741437.587700\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 18262.56, NNZs: 3, Bias: -193.113214, T: 5400, Avg. loss: 47736667.233234\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 23136.16, NNZs: 3, Bias: -193.039368, T: 5600, Avg. loss: 52024855.120507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 30608.20, NNZs: 3, Bias: -199.023428, T: 5800, Avg. loss: 36416617.232855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 15322.15, NNZs: 3, Bias: -208.758108, T: 6000, Avg. loss: 37024768.659542\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 17545.75, NNZs: 3, Bias: -194.639380, T: 6200, Avg. loss: 46403405.008290\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11577.57, NNZs: 3, Bias: -207.079475, T: 6400, Avg. loss: 37144450.506530\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12692.90, NNZs: 3, Bias: -212.405176, T: 6600, Avg. loss: 29195403.408555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 23239.73, NNZs: 3, Bias: -221.505585, T: 6800, Avg. loss: 30650521.658633\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11221.75, NNZs: 3, Bias: -219.064031, T: 7000, Avg. loss: 33110713.361357\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11562.46, NNZs: 3, Bias: -219.026462, T: 7200, Avg. loss: 30476915.977737\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 12162.85, NNZs: 3, Bias: -226.269056, T: 7400, Avg. loss: 35771824.479969\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 19564.70, NNZs: 3, Bias: -239.124737, T: 7600, Avg. loss: 36370991.813773\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 38 epochs took 0.03 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, loss='log', n_jobs=-1, random_state=15, verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.fit(d_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3925.14601273, -16033.05764291,  10502.94022174]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-239.12473731])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.2] SVM(SGDClassifier with hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "svm_clsfr: Support Vector Machine classifier\n",
    "\"\"\"\n",
    "svm_clsfr = linear_model.SGDClassifier(loss='hinge', eta0 = 0.0001, alpha = 0.0001, penalty = 'l2', random_state = 15, verbose = 2, n_jobs = -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 50970.78, NNZs: 3, Bias: -139.425296, T: 200, Avg. loss: 237646740.055412\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48251.18, NNZs: 3, Bias: -107.540533, T: 400, Avg. loss: 198997629.606033\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47283.82, NNZs: 3, Bias: -98.147510, T: 600, Avg. loss: 221678301.804550\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 42763.27, NNZs: 3, Bias: -203.499872, T: 800, Avg. loss: 184224165.832094\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46523.86, NNZs: 3, Bias: -208.473184, T: 1000, Avg. loss: 163252412.932515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19449.28, NNZs: 3, Bias: -203.212119, T: 1200, Avg. loss: 144245644.752882\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28910.00, NNZs: 3, Bias: -180.696759, T: 1400, Avg. loss: 130092109.903065\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 34971.40, NNZs: 3, Bias: -163.150693, T: 1600, Avg. loss: 121277810.479388\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 33276.26, NNZs: 3, Bias: -178.221644, T: 1800, Avg. loss: 105218983.318030\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 18314.88, NNZs: 3, Bias: -168.748680, T: 2000, Avg. loss: 105751075.568105\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 34026.26, NNZs: 3, Bias: -137.000345, T: 2200, Avg. loss: 104100927.952489\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 32060.64, NNZs: 3, Bias: -164.390101, T: 2400, Avg. loss: 85184284.955179\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 33408.49, NNZs: 3, Bias: -161.254990, T: 2600, Avg. loss: 94393954.300818\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 57260.17, NNZs: 3, Bias: -140.340518, T: 2800, Avg. loss: 69341260.386531\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 25327.28, NNZs: 3, Bias: -127.421971, T: 3000, Avg. loss: 61111146.019126\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29918.51, NNZs: 3, Bias: -151.478787, T: 3200, Avg. loss: 72048575.772406\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 25927.67, NNZs: 3, Bias: -163.617817, T: 3400, Avg. loss: 56499951.273764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 26840.99, NNZs: 3, Bias: -159.252208, T: 3600, Avg. loss: 61377838.704854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 16611.54, NNZs: 3, Bias: -165.343898, T: 3800, Avg. loss: 63182350.326400\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 17932.89, NNZs: 3, Bias: -181.588087, T: 4000, Avg. loss: 54754912.040320\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 20618.77, NNZs: 3, Bias: -183.713029, T: 4200, Avg. loss: 48531162.067885\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 17582.59, NNZs: 3, Bias: -160.795773, T: 4400, Avg. loss: 49205687.377794\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 12238.11, NNZs: 3, Bias: -151.631232, T: 4600, Avg. loss: 45051759.128370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12788.80, NNZs: 3, Bias: -163.778006, T: 4800, Avg. loss: 54258128.144688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 29238.53, NNZs: 3, Bias: -161.900288, T: 5000, Avg. loss: 47795204.045875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 17511.09, NNZs: 3, Bias: -168.326384, T: 5200, Avg. loss: 44003343.599421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 18947.25, NNZs: 3, Bias: -174.559104, T: 5400, Avg. loss: 45122963.443264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 25130.28, NNZs: 3, Bias: -179.174563, T: 5600, Avg. loss: 51090318.362048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 30142.91, NNZs: 3, Bias: -186.608547, T: 5800, Avg. loss: 36989720.994604\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 15148.98, NNZs: 3, Bias: -196.343227, T: 6000, Avg. loss: 36986359.783150\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 15145.60, NNZs: 3, Bias: -189.287735, T: 6200, Avg. loss: 39786508.825210\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11102.35, NNZs: 3, Bias: -189.476491, T: 6400, Avg. loss: 39212165.268714\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13179.57, NNZs: 3, Bias: -192.017279, T: 6600, Avg. loss: 31809325.675832\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 22709.10, NNZs: 3, Bias: -198.477941, T: 6800, Avg. loss: 29997166.152475\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11986.41, NNZs: 3, Bias: -203.648269, T: 7000, Avg. loss: 30788036.546377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11988.21, NNZs: 3, Bias: -204.837743, T: 7200, Avg. loss: 23108194.706015\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 12579.76, NNZs: 3, Bias: -214.481769, T: 7400, Avg. loss: 34582923.132730\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 24206.08, NNZs: 3, Bias: -222.667517, T: 7600, Avg. loss: 33918946.617544\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12470.53, NNZs: 3, Bias: -218.000666, T: 7800, Avg. loss: 34052236.991689\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11512.54, NNZs: 3, Bias: -223.624922, T: 8000, Avg. loss: 35026025.189644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 11169.92, NNZs: 3, Bias: -213.747039, T: 8200, Avg. loss: 28684903.853204\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 41 epochs took 0.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, n_jobs=-1, random_state=15, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.fit(d_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1441.65036452, -3083.88512888, 10638.5348658 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-213.74703893])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Task 2\n",
    "## [2.1] Logistic regression(SGDClassifier with logloss) after standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top {} rows of DataFrame : \n",
      "\n",
      "{} [3,             f1            f2        f3    y\n",
      "0  -195.871045 -14843.084171  5.532140  1.0\n",
      "1 -1217.183964  -4068.124621  4.416082  1.0\n",
      "2     9.138451   4413.412028  0.425317  0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top {} rows of DataFrame : \\n\\n{}\", [3, data.head(n = 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_feature_nda = data['f1'].values.reshape(-1, 1)\n",
    "\n",
    "scaler.fit(f1_feature_nda)\n",
    "data['f1_transform'] = scaler.transform(f1_feature_nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f2_feature_nda = data['f2'].values.reshape(-1, 1)\n",
    "\n",
    "scaler.fit(f2_feature_nda)\n",
    "data['f2_transform'] = scaler.transform(f2_feature_nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_feature_nda = data['f3'].values.reshape(-1, 1)\n",
    "\n",
    "scaler.fit(f3_feature_nda)\n",
    "data['f3_transform'] = scaler.transform(f3_feature_nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top {} rows of DataFrame : \n",
      "\n",
      "{} [3,             f1            f2        f3    y  f1_transform  f2_transform  \\\n",
      "0  -195.871045 -14843.084171  5.532140  1.0     -0.423126     -1.555602   \n",
      "1 -1217.183964  -4068.124621  4.416082  1.0     -2.520394     -0.517290   \n",
      "2     9.138451   4413.412028  0.425317  0.0     -0.002139      0.300020   \n",
      "\n",
      "   f3_transform  \n",
      "0      0.181651  \n",
      "1     -0.200648  \n",
      "2     -1.567659  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top {} rows of DataFrame : \\n\\n{}\", [3, data.head(n = 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Data Type of d_train_std: {} [<class 'numpy.ndarray'>]\n",
      "2. Shape of d_train_std: {}\n",
      "\n",
      " [(200, 3)]\n",
      "1. Data Type of y: {} [<class 'numpy.ndarray'>]\n",
      "2. Shape of y:  [(200,)]\n"
     ]
    }
   ],
   "source": [
    "d_train_std = data[['f1_transform', 'f2_transform', 'f3_transform']].values\n",
    "print(\"1. Data Type of d_train_std: {}\", [type(d_train_std)])\n",
    "print(\"2. Shape of d_train_std: {}\\n\\n\", [d_train_std.shape])\n",
    "\n",
    "\n",
    "print(\"1. Data Type of y: {}\", [type(y)])\n",
    "print(\"2. Shape of y: \", [y.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 53.31, NNZs: 3, Bias: -5.276812, T: 200, Avg. loss: 1.866743\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.34, NNZs: 3, Bias: 3.430650, T: 400, Avg. loss: 1.352641\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.99, NNZs: 3, Bias: 2.140512, T: 600, Avg. loss: 1.213044\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.54, NNZs: 3, Bias: -5.951509, T: 800, Avg. loss: 1.279978\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32.19, NNZs: 3, Bias: 1.875443, T: 1000, Avg. loss: 0.999923\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.45, NNZs: 3, Bias: -0.998614, T: 1200, Avg. loss: 0.563070\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 32.57, NNZs: 3, Bias: 2.720694, T: 1400, Avg. loss: 0.687991\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 30.51, NNZs: 3, Bias: -2.435934, T: 1600, Avg. loss: 0.722018\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 28.04, NNZs: 3, Bias: -3.174216, T: 1800, Avg. loss: 0.807365\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 23.99, NNZs: 3, Bias: -2.572984, T: 2000, Avg. loss: 0.553149\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 22.28, NNZs: 3, Bias: -2.147460, T: 2200, Avg. loss: 0.411893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 20.19, NNZs: 3, Bias: 0.627308, T: 2400, Avg. loss: 0.529198\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 21.56, NNZs: 3, Bias: -2.041266, T: 2600, Avg. loss: 0.605205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 19.78, NNZs: 3, Bias: -1.691095, T: 2800, Avg. loss: 0.510316\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 18.38, NNZs: 3, Bias: 1.544255, T: 3000, Avg. loss: 0.352165\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 19.07, NNZs: 3, Bias: 2.411612, T: 3200, Avg. loss: 0.394782\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 18.00, NNZs: 3, Bias: -2.138986, T: 3400, Avg. loss: 0.306954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 16.71, NNZs: 3, Bias: -5.620388, T: 3600, Avg. loss: 0.323921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 17.02, NNZs: 3, Bias: 0.057260, T: 3800, Avg. loss: 0.372382\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 14.89, NNZs: 3, Bias: -0.230625, T: 4000, Avg. loss: 0.374575\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 13.71, NNZs: 3, Bias: -2.768940, T: 4200, Avg. loss: 0.462690\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 13.42, NNZs: 3, Bias: 0.939680, T: 4400, Avg. loss: 0.275341\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 12.14, NNZs: 3, Bias: -2.044632, T: 4600, Avg. loss: 0.352880\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12.77, NNZs: 3, Bias: -2.295930, T: 4800, Avg. loss: 0.378551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 13.33, NNZs: 3, Bias: -1.451579, T: 5000, Avg. loss: 0.187752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12.28, NNZs: 3, Bias: -0.251063, T: 5200, Avg. loss: 0.334557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12.67, NNZs: 3, Bias: 0.332995, T: 5400, Avg. loss: 0.328642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11.20, NNZs: 3, Bias: -0.431264, T: 5600, Avg. loss: 0.321415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11.61, NNZs: 3, Bias: -1.026621, T: 5800, Avg. loss: 0.273815\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.38, NNZs: 3, Bias: -0.726479, T: 6000, Avg. loss: 0.353289\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 30 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, loss='log', n_jobs=-1, random_state=15, verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.fit(d_train_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29741788, -0.66973479, 10.35436789]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.72647926])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clsfr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2.2] SVM(SGDClassifier with hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 42.77, NNZs: 3, Bias: -0.401235, T: 200, Avg. loss: 2.007617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41.12, NNZs: 3, Bias: -0.275640, T: 400, Avg. loss: 1.330494\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.84, NNZs: 3, Bias: 0.082357, T: 600, Avg. loss: 1.548790\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.91, NNZs: 3, Bias: -5.367733, T: 800, Avg. loss: 1.324727\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33.04, NNZs: 3, Bias: -0.044521, T: 1000, Avg. loss: 0.970131\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33.35, NNZs: 3, Bias: -4.658497, T: 1200, Avg. loss: 0.786032\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 33.34, NNZs: 3, Bias: 4.123484, T: 1400, Avg. loss: 1.002599\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 35.12, NNZs: 3, Bias: -0.193457, T: 1600, Avg. loss: 0.904594\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 32.42, NNZs: 3, Bias: -3.925287, T: 1800, Avg. loss: 1.007940\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 30.21, NNZs: 3, Bias: -0.390801, T: 2000, Avg. loss: 0.937491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.78, NNZs: 3, Bias: -0.439292, T: 2200, Avg. loss: 0.573288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.34, NNZs: 3, Bias: -0.483781, T: 2400, Avg. loss: 0.769558\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 25.69, NNZs: 3, Bias: -3.347256, T: 2600, Avg. loss: 0.878631\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 25.03, NNZs: 3, Bias: -0.697268, T: 2800, Avg. loss: 0.586768\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 22.47, NNZs: 3, Bias: -0.729693, T: 3000, Avg. loss: 0.657703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 22.51, NNZs: 3, Bias: -0.774151, T: 3200, Avg. loss: 0.580925\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 16 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, n_jobs=-1, random_state=15, verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.fit(d_train_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.23347737,  0.46842383, 22.39791493]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.77415149])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clsfr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "8B_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
